# llm-server
Trying to server llm with OpenAI API locally
